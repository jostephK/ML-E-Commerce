{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BZJxcIdrKs_",
    "outputId": "579e6b43-28af-4239-ff98-6e1d2cab4041"
   },
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install plotly.express\n",
    "%pip install --upgrade nbformat\n",
    "%pip install numpy\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "from data.preprocessing import preprocess_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hooci9uqrKtA"
   },
   "source": [
    "We will use k-means to cluster our data into 5 clusters: very expensive low-quantity items, expensive low-quantity items, cheap low-quantity items, cheap moderate-quantity items, and cheap bulk items.\n",
    "\n",
    "We first import our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8E-iVvZPrKtB",
    "outputId": "3eeb7102-856e-48d9-f13a-6986a4c83d77"
   },
   "outputs": [],
   "source": [
    "dataset_original = pd.read_csv('data/data.csv', encoding='latin1')\n",
    "preprocessed_dataset = preprocess_csv('data/data.csv', ['StockCode', 'InvoiceDate'])\n",
    "preprocessed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy7ElQ1QrKtB"
   },
   "source": [
    "As you can see, we have a lot of datapoints (541909), but the only features we're currently worried about is quantity and unit price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "yhcjtSpUrKtB",
    "outputId": "85b77e19-26f5-4d25-a8b7-5132da8ac324"
   },
   "outputs": [],
   "source": [
    "dataframe = preprocessed_dataset[[\"Quantity\", \"UnitPrice\"]]\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "dcHbpPlerKtC",
    "outputId": "afce7a9e-2385-4bd0-cd35-6c29562a477c"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(dataframe, x='Quantity', y='UnitPrice')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWxkApZRrKtC"
   },
   "source": [
    "We need to clean up our dataset a little bit. Namely, we have some negative quantites (returned items), and many duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5ByJkASnrKtC",
    "outputId": "09fa0c85-7c25-4498-c99c-95d8ea71cdae"
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop_duplicates()\n",
    "dataframe = dataframe[(dataframe >= 0).all(axis=1)]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "ogQ7oQFErKtC",
    "outputId": "6a6665b8-34db-4039-9137-023fb3c8a67f"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(dataframe, x='Quantity', y='UnitPrice')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwfy_VilrKtC"
   },
   "source": [
    "Now deleting some outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "BhqpgsqnrKtC",
    "outputId": "46d60d45-2308-4dfc-d730-b9d7c529ed1c"
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe[(dataframe < 3000).all(axis=1)]\n",
    "npdata = dataframe.to_numpy()\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "0kvry7ubrKtC",
    "outputId": "42f8d540-0eaf-429d-9cff-a5bb6a963577"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(dataframe, x='Quantity', y='UnitPrice')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vv1ZwRMxrKtD"
   },
   "outputs": [],
   "source": [
    "def update_assignments(centers, points):\n",
    "\txsquare = np.square(centers)\n",
    "\txsquare = np.sum(xsquare, axis=1, keepdims=True)\n",
    "\tysquare = np.square(points)\n",
    "\tysquare = np.sum(ysquare, axis=1, keepdims=True)\n",
    "\txy = np.dot(centers, points.T)\n",
    "\tdistances = np.sqrt(xsquare + ysquare.T - 2 * xy)\n",
    "\n",
    "\treturn np.argmin(distances, axis=0)\n",
    "\n",
    "def update_centers(points, assignments, K):\n",
    "\treturnList = []\n",
    "\n",
    "\tfor i in range(K):\n",
    "\t\tindices = np.where(assignments == i)\n",
    "\t\tcurrPoints = np.take(points, indices[0], axis=0)\n",
    "\t\tsize = currPoints.shape[0]\n",
    "\t\tif size != 0:\n",
    "\t\t\tcurrPoints = np.sum(currPoints, axis=0)\n",
    "\t\t\tcurrPoints /= size\n",
    "\t\t\treturnList.append(currPoints)\n",
    "\n",
    "\treturn np.array(returnList)\n",
    "\n",
    "def get_loss(points, centers, assignments):\n",
    "\treturn np.linalg.norm((points - centers[assignments])).sum() ** 2\n",
    "\n",
    "def train(data, centers, K=5, max_iters=10000, rel_tol = 1e-05):\n",
    "\titeration = 0\n",
    "\tcurrCenters = centers\n",
    "\n",
    "\twhile iteration < max_iters:\n",
    "\t\tassignments = update_assignments(currCenters, data)\n",
    "\t\tcurrCenters = update_centers(data, assignments, K)\n",
    "\n",
    "\t\t#Make sure we retain number of centers\n",
    "\t\twhile centers.shape[0] < K:\n",
    "\t\t\tnewCenter = data[np.random.choice(data.shape[0])]\n",
    "\t\t\tcurrCenters = np.vstack((currCenters, newCenter))\n",
    "\t\t\tassignments = update_assignments(currCenters, data)\n",
    "\t\tcurrLoss = get_loss(data, currCenters, assignments)\n",
    "\t\tif iteration > 0:\n",
    "\t\t\tif (np.abs(prevLoss - currLoss) / prevLoss < rel_tol):\n",
    "\t\t\t\tbreak\n",
    "\t\tprevLoss = currLoss\n",
    "\t\titeration += 1\n",
    "\treturn currCenters, assignments, currLoss\n",
    "\n",
    "\n",
    "centers, assignments, loss = train(npdata, np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5,5]]))\n",
    "#We can use dummy centers and still end up with the same result.\n",
    "\n",
    "colored_data = np.hstack((npdata, assignments.reshape((-1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "sYDqXnIXrKtD",
    "outputId": "abd3d8b9-9dd8-41eb-d2e8-248d74be274d"
   },
   "outputs": [],
   "source": [
    "colored_dataframe = pd.DataFrame(colored_data, columns=[\"Quantity\", \"UnitPrice\", \"Assignment\"])\n",
    "\n",
    "fig = px.scatter(colored_dataframe, x=\"Quantity\", y=\"UnitPrice\", color=\"Assignment\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzjiSf0_rKtD"
   },
   "source": [
    "In this graph, the colors represent:  \n",
    "Orange-- Very expensive items that are bought in fery low quantities  \n",
    "Purple-- Moderately expensive items that are bought in very low quantities  \n",
    "Blue-- Cheap items that are bought in low to moderate quantities  \n",
    "Pink-- Cheap items that are bought in moderate to high quantities  \n",
    "Yellow-- Cheap items that are bought in very high quantities  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAfH05jorKtD"
   },
   "outputs": [],
   "source": [
    "orange = []\n",
    "purple = []\n",
    "blue = []\n",
    "pink = []\n",
    "yellow = []\n",
    "\n",
    "\n",
    "for i in list(dataframe.index):\n",
    "    j = 0\n",
    "    currColor = colored_dataframe.iloc[j][\"Assignment\"]\n",
    "    if currColor == 0.0:\n",
    "        blue.append(dataset_original.iloc[i][\"Description\"])\n",
    "    elif currColor == 1.0:\n",
    "        purple.append(dataset_original.iloc[i][\"Description\"])\n",
    "    elif currColor == 2.0:\n",
    "        pink.append(dataset_original.iloc[i][\"Description\"])\n",
    "    elif currColor == 3.0:\n",
    "        orange.append(dataset_original.iloc[i][\"Description\"])\n",
    "    else:\n",
    "        yellow.append(dataset_original.iloc[i][\"Description\"])\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqI3EECirKtE"
   },
   "source": [
    "Now, we have 5 lists of item descriptions -- one for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-mean evaluation using Silhoutte Score\n",
    "\n",
    "def calculate_silhouette_score(points, assignments, centers):\n",
    "    n_points = points.shape[0]\n",
    "    silhouette_scores = np.zeros(n_points)\n",
    "    for i in range(n_points):\n",
    "        current_cluster = assignments[i]\n",
    "        same_cluster_points = points[assignments == current_cluster]\n",
    "        if len(same_cluster_points) > 1:\n",
    "            a_i = np.mean(np.linalg.norm(same_cluster_points - points[i], axis=1))\n",
    "        else:\n",
    "            a_i = 0\n",
    "        b_i = float('inf')\n",
    "        for k in range(centers.shape[0]):\n",
    "            if k != current_cluster:\n",
    "                other_cluster_points = points[assignments == k]\n",
    "                if other_cluster_points.size > 0:\n",
    "                    avg_dist_to_other_cluster = np.mean(np.linalg.norm(other_cluster_points - points[i], axis=1))\n",
    "                    b_i = min(b_i, avg_dist_to_other_cluster)\n",
    "        if max(a_i, b_i) > 0:\n",
    "            silhouette_scores[i] = (b_i - a_i) / max(a_i, b_i)\n",
    "        else:\n",
    "            silhouette_scores[i] = 0 \n",
    "    return np.mean(silhouette_scores)\n",
    "silhouette_score = calculate_silhouette_score(npdata, assignments, centers)\n",
    "\n",
    "silhouette_score"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
